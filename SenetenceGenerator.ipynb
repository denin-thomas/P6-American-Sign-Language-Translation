{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a36769-9811-4e56-a55c-e195b08b560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Load your trained model\n",
    "model = tf.keras.models.load_model(\"modelAdditionalLayers4001.keras\")\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False,\n",
    "                       max_num_hands=1,\n",
    "                       min_detection_confidence=0.5,\n",
    "                       min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "labels = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\n",
    "\n",
    "def draw_hand_landmarks_on_black(hand_landmarks, image_size=128):\n",
    "    landmarks = np.array([[lm.x, lm.y] for lm in hand_landmarks.landmark])\n",
    "    x_vals, y_vals = landmarks[:, 0], landmarks[:, 1]\n",
    "    min_x, max_x = np.min(x_vals), np.max(x_vals)\n",
    "    min_y, max_y = np.min(y_vals), np.max(y_vals)\n",
    "\n",
    "    width = max_x - min_x\n",
    "    height = max_y - min_y\n",
    "    scale = 0.7 * image_size / max(width, height)\n",
    "\n",
    "    landmarks[:, 0] = (landmarks[:, 0] - min_x) * scale\n",
    "    landmarks[:, 1] = (landmarks[:, 1] - min_y) * scale\n",
    "\n",
    "    offset_x = (image_size - width * scale) / 2\n",
    "    offset_y = (image_size - height * scale) / 2\n",
    "    landmarks[:, 0] += offset_x\n",
    "    landmarks[:, 1] += offset_y\n",
    "\n",
    "    black_img = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "    landmark_points = landmarks.astype(np.int32)\n",
    "\n",
    "    for connection in mp_hands.HAND_CONNECTIONS:\n",
    "        start = tuple(landmark_points[connection[0]])\n",
    "        end = tuple(landmark_points[connection[1]])\n",
    "        cv2.line(black_img, start, end, (0, 255, 0), 1)\n",
    "\n",
    "    for point in landmark_points:\n",
    "        cv2.circle(black_img, tuple(point), 1, (0, 255, 0), -1)\n",
    "\n",
    "    return black_img\n",
    "\n",
    "# Real-time tracking variables\n",
    "sentence = \"\"\n",
    "current_letter = \"\"\n",
    "confirmed_letter = \"\"\n",
    "stable_count = 0\n",
    "last_confirmed_time = time.time()\n",
    "last_frame_time = time.time()\n",
    "no_hand_start_time = None\n",
    "\n",
    "# Configurable thresholds\n",
    "STABILITY_THRESHOLD = 3\n",
    "LETTER_COOLDOWN = 1.0  # Seconds to allow repeat letter\n",
    "NO_HAND_TIMEOUT = 2.0  # Seconds to separate words\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    prediction_text = \"Waiting for hand...\"\n",
    "\n",
    "    current_time = time.time()\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        no_hand_start_time = None  # Reset no-hand timer\n",
    "\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            colored_img = draw_hand_landmarks_on_black(hand_landmarks, image_size=128)\n",
    "            gray_img = cv2.cvtColor(colored_img, cv2.COLOR_BGR2GRAY)\n",
    "            normalized_img = gray_img.astype(\"float32\") / 255.0\n",
    "            input_img = np.expand_dims(normalized_img, axis=(0, -1))\n",
    "\n",
    "            prediction = model.predict(input_img, verbose=0)\n",
    "            predicted_index = np.argmax(prediction)\n",
    "            confidence = prediction[0][predicted_index]\n",
    "\n",
    "            if confidence > 0.8:\n",
    "                predicted_letter = labels[predicted_index]\n",
    "\n",
    "                if predicted_letter == confirmed_letter:\n",
    "                    stable_count += 1\n",
    "                else:\n",
    "                    stable_count = 0\n",
    "                    confirmed_letter = predicted_letter\n",
    "\n",
    "                if stable_count > STABILITY_THRESHOLD:\n",
    "                    # Accept letter only if enough time has passed since last one\n",
    "                    if (current_letter != confirmed_letter) or (current_time - last_confirmed_time > LETTER_COOLDOWN):\n",
    "                        sentence += confirmed_letter\n",
    "                        current_letter = confirmed_letter\n",
    "                        last_confirmed_time = current_time\n",
    "                    prediction_text = f\"Letter: {confirmed_letter}\"\n",
    "                else:\n",
    "                    prediction_text = f\"Stabilizing: {confirmed_letter}\"\n",
    "            else:\n",
    "                prediction_text = \"Unsure\"\n",
    "\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            cv2.imshow(\"Model Input\", colored_img)\n",
    "            break  # Use only the first hand\n",
    "    else:\n",
    "        # Handle no hand detected (to insert space)\n",
    "        if no_hand_start_time is None:\n",
    "            no_hand_start_time = current_time\n",
    "        elif current_time - no_hand_start_time > NO_HAND_TIMEOUT:\n",
    "            if not sentence.endswith(\" \"):\n",
    "                sentence += \" \"  # Add space to separate words\n",
    "            no_hand_start_time = None  # Prevent multiple spaces\n",
    "\n",
    "    # Show sentence above frame\n",
    "    cv2.putText(frame, prediction_text, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Sentence: {sentence}\", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    cv2.imshow(\"ASL to Sentence\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45beb83a-f4ac-4473-addb-07a30d04f7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70337d57-685d-4ba9-ae38-f3995e458e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aienv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
