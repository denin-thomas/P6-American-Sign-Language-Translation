{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a36769-9811-4e56-a55c-e195b08b560f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Denin\n",
      "[nltk_data]     Thomas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Denin\n",
      "[nltk_data]     Thomas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Sentence: H NN Q.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "import re\n",
    "\n",
    "# Initialize NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load your trained model\n",
    "model = tf.keras.models.load_model(\"modelAdditionalLayers.keras\")\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False,\n",
    "                      max_num_hands=1,\n",
    "                      min_detection_confidence=0.7,\n",
    "                      min_tracking_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# ASL Labels (A-Z)\n",
    "labels = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\n",
    "\n",
    "# Ambiguous ASL corrections\n",
    "ASL_COMMON_ERRORS = {\n",
    "    'A':'E', 'B': 'V', 'D': 'F', 'E': 'M',\n",
    "    'G': 'Q', 'I': 'J', 'K': 'P', 'M': 'N',\n",
    "    'S': 'A', 'V': 'B', 'F': 'D', 'N': 'M'\n",
    "}\n",
    "\n",
    "# Common ASL words\n",
    "ASL_COMMON_WORDS = {\n",
    "    'HELLO', 'WORLD', 'THANK', 'YOU', 'YES', 'NO', \n",
    "    'PLEASE', 'SORRY', 'HELP', 'NAME', 'MY', 'WHAT',\n",
    "    'WHERE', 'WHEN', 'WHY', 'HOW', 'MEET', 'AGAIN',\n",
    "    'GOOD', 'MORNING', 'AFTERNOON', 'NIGHT', 'I', 'LOVE'\n",
    "}\n",
    "\n",
    "def draw_hand_landmarks_on_black(hand_landmarks, image_size=128):\n",
    "    landmarks = np.array([[lm.x, lm.y] for lm in hand_landmarks.landmark])\n",
    "    x_vals, y_vals = landmarks[:, 0], landmarks[:, 1]\n",
    "    min_x, max_x = np.min(x_vals), np.max(x_vals)\n",
    "    min_y, max_y = np.min(y_vals), np.max(y_vals)\n",
    "    width, height = max_x - min_x, max_y - min_y\n",
    "    scale = 0.8 * image_size / max(width, height)\n",
    "\n",
    "    landmarks[:, 0] = (landmarks[:, 0] - min_x) * scale\n",
    "    landmarks[:, 1] = (landmarks[:, 1] - min_y) * scale\n",
    "    landmarks[:, 0] += (image_size - width * scale) / 2\n",
    "    landmarks[:, 1] += (image_size - height * scale) / 2\n",
    "\n",
    "    black_img = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "    points = landmarks.astype(np.int32)\n",
    "\n",
    "    for connection in mp_hands.HAND_CONNECTIONS:\n",
    "        start = tuple(points[connection[0]])\n",
    "        end = tuple(points[connection[1]])\n",
    "        cv2.line(black_img, start, end, (0, 255, 0), 2)\n",
    "\n",
    "    for point in points:\n",
    "        cv2.circle(black_img, tuple(point), 3, (0, 255, 0), -1)\n",
    "\n",
    "    return black_img\n",
    "\n",
    "def pre_correct_letter(letter):\n",
    "    return ASL_COMMON_ERRORS.get(letter, letter)\n",
    "\n",
    "def auto_correct_word(word):\n",
    "    if len(word) <= 1:\n",
    "        return word\n",
    "    corrected = ''.join([pre_correct_letter(c) for c in word])\n",
    "    if corrected in ASL_COMMON_WORDS:\n",
    "        return corrected\n",
    "    try:\n",
    "        tb = TextBlob(corrected)\n",
    "        if tb.words:\n",
    "            suggestion, confidence = tb.words[0].spellcheck()[0]\n",
    "            return suggestion if confidence > 0.7 else corrected\n",
    "    except:\n",
    "        pass\n",
    "    return corrected\n",
    "\n",
    "def format_sentence(raw_sentence):\n",
    "    if not raw_sentence:\n",
    "        return \"\"\n",
    "    words = raw_sentence.split()\n",
    "    if words:\n",
    "        words[0] = words[0].capitalize()\n",
    "    if words and not raw_sentence.endswith(('.', '!', '?')):\n",
    "        words[-1] += '.'\n",
    "    formatted = ' '.join(words)\n",
    "    formatted = formatted.replace(\" i \", \" I \")\n",
    "    formatted = formatted.replace(\" i'm \", \" I'm \")\n",
    "    formatted = formatted.replace(\" i've \", \" I've \")\n",
    "    return formatted\n",
    "\n",
    "raw_sentence = []\n",
    "current_word = []\n",
    "confirmed_letter = \"\"\n",
    "stable_count = 0\n",
    "last_confirmed_time = time.time()\n",
    "no_hand_start_time = None\n",
    "last_letter_time = time.time()\n",
    "\n",
    "STABILITY_THRESHOLD = 5\n",
    "LETTER_COOLDOWN = 0.5\n",
    "NO_HAND_TIMEOUT = 2.0\n",
    "WORD_TIMEOUT = 3.0\n",
    "MIN_WORD_LENGTH = 3\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"ASL Translator\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "    current_time = time.time()\n",
    "\n",
    "    prediction_text = \"Show hand sign...\"\n",
    "    current_letter = \"\"\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        no_hand_start_time = None\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            hand_img = draw_hand_landmarks_on_black(hand_landmarks)\n",
    "            gray_img = cv2.cvtColor(hand_img, cv2.COLOR_BGR2GRAY)\n",
    "            normalized_img = gray_img.astype(\"float32\") / 255.0\n",
    "            input_img = np.expand_dims(normalized_img, axis=(0, -1))\n",
    "\n",
    "            prediction = model.predict(input_img, verbose=0)\n",
    "            predicted_index = np.argmax(prediction)\n",
    "            confidence = prediction[0][predicted_index]\n",
    "\n",
    "            if predicted_index < len(labels) and confidence > 0.85:\n",
    "                predicted_letter = labels[predicted_index]\n",
    "                if predicted_letter == confirmed_letter:\n",
    "                    stable_count += 1\n",
    "                else:\n",
    "                    stable_count = 0\n",
    "                    confirmed_letter = predicted_letter\n",
    "\n",
    "                if stable_count > STABILITY_THRESHOLD:\n",
    "                    prediction_text = f\"Letter: {confirmed_letter}\"\n",
    "                    current_letter = confirmed_letter\n",
    "                else:\n",
    "                    prediction_text = f\"Detecting: {confirmed_letter}\"\n",
    "\n",
    "                if (stable_count > STABILITY_THRESHOLD and \n",
    "                    (current_time - last_letter_time > LETTER_COOLDOWN)):\n",
    "                    current_word.append(confirmed_letter)\n",
    "                    last_letter_time = current_time\n",
    "                    last_confirmed_time = current_time\n",
    "                    stable_count = 0\n",
    "\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            cv2.imshow(\"Hand Input\", hand_img)\n",
    "            break\n",
    "    else:\n",
    "        if no_hand_start_time is None:\n",
    "            no_hand_start_time = current_time\n",
    "        elif current_time - no_hand_start_time > NO_HAND_TIMEOUT:\n",
    "            if current_word:\n",
    "                word = ''.join(current_word)\n",
    "                corrected_word = auto_correct_word(word)\n",
    "                raw_sentence.append(corrected_word)\n",
    "                current_word = []\n",
    "            no_hand_start_time = None\n",
    "\n",
    "    if current_word and (current_time - last_letter_time > WORD_TIMEOUT):\n",
    "        word = ''.join(current_word)\n",
    "        corrected_word = auto_correct_word(word)\n",
    "        raw_sentence.append(corrected_word)\n",
    "        current_word = []\n",
    "\n",
    "    display_word = auto_correct_word(''.join(current_word)) if current_word else \"\"\n",
    "    full_sentence = format_sentence(' '.join(raw_sentence + [display_word]))\n",
    "\n",
    "    y_offset = 40\n",
    "    cv2.putText(frame, prediction_text, (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    y_offset += 40\n",
    "\n",
    "    cv2.putText(frame, f\"Current: {display_word}\", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "    y_offset += 40\n",
    "\n",
    "    cv2.putText(frame, f\"Sentence: {full_sentence}\", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    y_offset += 40\n",
    "\n",
    "    cv2.imshow(\"ASL Translator\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "if current_word:\n",
    "    raw_sentence.append(auto_correct_word(''.join(current_word)))\n",
    "\n",
    "print(\"\\nFinal Sentence:\", format_sentence(' '.join(raw_sentence)))\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45beb83a-f4ac-4473-addb-07a30d04f7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70337d57-685d-4ba9-ae38-f3995e458e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aienv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
